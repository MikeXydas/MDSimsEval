{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning on 5HT2A Receptor\n",
    "\n",
    "Goal of this notebook is to use the features extracted and analyzed on the other Analysis notebook.  \n",
    "We want to differentiate agonist ligands from antagonists using features extracted from the MD simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T08:21:23.946145Z",
     "start_time": "2020-04-28T08:21:22.111168Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from AnalysisActor.AnalysisActorClass import AnalysisActor\n",
    "from AnalysisActor.utils import create_analysis_actor_dict\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "import logging\n",
    "import math\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T09:00:19.399539Z",
     "start_time": "2020-04-25T09:00:19.396637Z"
    }
   },
   "source": [
    "## Reading the Simulations\n",
    "\n",
    "We will use the `AnalysisActor` package I wrote which is able to extract on low level features from the simulations. I call it low level since for example the `AnalysisActor.class` of a ligand will give us the $Rg$ of the ligand on each frame. This must be then reduced to features that I have analyzed like mean and std for each ligand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T08:23:48.119592Z",
     "start_time": "2020-04-28T08:21:26.063524Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Agonists | Lorcaserin:   7%|▋         | 1/15 [00:02<00:31,  2.24s/it]/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/MDAnalysis/lib/mdamath.py:259: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  alpha = np.rad2deg(np.arccos(np.dot(y, z) / (ly * lz)))\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/MDAnalysis/lib/mdamath.py:260: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  beta = np.rad2deg(np.arccos(np.dot(x, z) / (lx * lz)))\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/MDAnalysis/lib/mdamath.py:261: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  gamma = np.rad2deg(np.arccos(np.dot(x, y) / (lx * ly)))\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/MDAnalysis/lib/mdamath.py:264: RuntimeWarning: invalid value encountered in greater\n",
      "  if np.all(box > 0.0) and alpha < 180.0 and beta < 180.0 and gamma < 180.0:\n",
      "Agonists | Donitriptan: 100%|██████████| 15/15 [00:35<00:00,  2.34s/it]  \n",
      "Antagonists | Ziprasione: 100%|██████████| 18/18 [01:46<00:00,  5.94s/it]   \n"
     ]
    }
   ],
   "source": [
    "# Reading the simulations\n",
    "analysis_actors_dict = create_analysis_actor_dict('../datasets/New_AI_MD/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `analysis_actors_dict` is a dictionary:\n",
    "```python \n",
    "{\n",
    "    \"Agonists\": List[AnalysisActor.class]\n",
    "    \"Antagonists\": List[AnalysisActor.class]\n",
    "}\n",
    "```\n",
    "This dictionary currently has only read the trajectories and has not calculated any of its metrics.  In order to do that we must call the `AnalysisActor.perform_analysis` method, which takes as an argument a list of metrics to be calculated.  \n",
    "  \n",
    "**Care**: The calculations need memory in order to be calculated and stored, so monitor the memory usage. If this becomes too big of a problem we can solve it in a \"dynamic\" way meaning that we will not keep saved the trajectories but demand them briefly for the calculations to be executed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T08:25:09.235842Z",
     "start_time": "2020-04-28T08:23:48.152720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8067343a3884421abcfda29d41a3249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ligand Calculations', max=33.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Possible arguments for \"metrics\" list:\n",
    "#     Empty List [] (default): All of the available metrics will be calculated\n",
    "#     'Rg': Radius of Gyration\n",
    "#     'RMSF': Root Mean Square Fluctuations\n",
    "#     'SASA': Solvent Accessible Surface Area\n",
    "#     'PCA': Principal Component Analysis\n",
    "#     'Hbonds': Hydrogen Bonds\n",
    "#     'Salt': Calculate number of salt bridges\n",
    "\n",
    "# Iterate on all the ligands\n",
    "for which_ligand in tqdm(analysis_actors_dict['Agonists'] + analysis_actors_dict['Antagonists'], desc=\"Ligand Calculations\"):\n",
    "    which_ligand.perform_analysis(metrics=[\"Rg\", \"SASA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the Features\n",
    "\n",
    "From the calculations we must now extract ML appropriate features. The features used in our case are:\n",
    "* Mean of Rg\n",
    "* Std of Rg\n",
    "* Mean of SASA\n",
    "* Std of SASA\n",
    "\n",
    "One parameter one must think of is the window of the features. Our simulations are of 2.500 and using all of them may  not be ideal. Our analysis actually shows that the event happens after 1.200 frames in most cases. However, as a starting point we will use all of the frames.  \n",
    "  \n",
    "**As labels we will use:**\n",
    "* Agonist: 1\n",
    "* Antagonist: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T08:29:51.509493Z",
     "start_time": "2020-04-28T08:29:51.491814Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset(analysis_actors_dict, start=0, stop=2500):\n",
    "    \"\"\"\n",
    "    Creates the df containing the feature columns and as the last column the labels.\n",
    "    Currently the features are Rg mean, Rg std, SASA mean, SASA std.\n",
    "    \n",
    "    Args:\n",
    "        analysis_actors_dict:   {\n",
    "                                    \"Agonists\": List[AnalysisActor.class]\n",
    "                                    \"Antagonists\": List[AnalysisActor.class]\n",
    "                                }\n",
    "                                \n",
    "        start(int): The starting frame of the simulation we are using for the features\n",
    "        stop(int): The starting last of the simulation we are using for the features\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame of #ligands rows and #features + 1 (for the labels) columns \n",
    "        \n",
    "    \"\"\"\n",
    "    full_dataset = []\n",
    "    \n",
    "    # Iterate on the agonists\n",
    "    for which_ligand in analysis_actors_dict['Agonists']:\n",
    "        # Rg\n",
    "        mean_rg = np.mean(which_ligand.get_radius_of_gyration()[start:stop])\n",
    "        std_rg = np.std(which_ligand.get_radius_of_gyration()[start:stop])\n",
    "\n",
    "        # SASA\n",
    "        mean_sasa = np.mean(which_ligand.get_sasa()[1][start:stop])\n",
    "        std_sasa = np.std(which_ligand.get_sasa()[1][start:stop])\n",
    "\n",
    "        # For each ligand we will create a vector of [Mean Rg, Std Rg, Mean SASA, Std SASA, Ligand_Label]\n",
    "        full_dataset.append([mean_rg, std_rg, mean_sasa, std_sasa, 1])\n",
    "\n",
    "    # Iterate on the antagonists\n",
    "    for which_ligand in analysis_actors_dict['Antagonists']:\n",
    "        # Rg\n",
    "        mean_rg = np.mean(which_ligand.get_radius_of_gyration()[start:stop])\n",
    "        std_rg = np.std(which_ligand.get_radius_of_gyration()[start:stop])\n",
    "\n",
    "        # SASA\n",
    "        mean_sasa = np.mean(which_ligand.get_sasa()[1][start:stop])\n",
    "        std_sasa = np.std(which_ligand.get_sasa()[1][start:stop])\n",
    "\n",
    "        # For each ligand we will create a vector of [Mean Rg, Std Rg, Mean SASA, Std SASA, Ligand_Label]\n",
    "        full_dataset.append([mean_rg, std_rg, mean_sasa, std_sasa, 0])\n",
    "\n",
    "    dataset_df = pd.DataFrame(full_dataset, columns=['RgMean', 'RgStd', 'SASAMean', 'SASAstd', 'LigandLabel'])\n",
    "    \n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating\n",
    "\n",
    "\n",
    "The main problem in our task is the little number of data points. This means that a good (or bad) result may be random and not reflect the reality.  \n",
    "Having the hyperparameters chosen (either by us or the tuning part of my pipeline) we must evaluate and analyze the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T09:49:36.354670Z",
     "start_time": "2020-04-28T09:49:36.332476Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_params(estimator, X, y, folds=5, verbose=True):\n",
    "    \"\"\"\n",
    "    Given an object estimator calculate Acc, f1, rec, auc using k-fold cross validation. This can be further\n",
    "    expanded to create confusion matrices.\n",
    "    \n",
    "    Args:\n",
    "        estimator (estimator Object): Object implementing the scikit-learn estimator interface\n",
    "        X (np.array): Matrix of the features of the input dataset\n",
    "        y (np.array): Vector of the labels of the ligands\n",
    "        folds (int): Number of fold of the CV\n",
    "        verbose (boolean): Currently chooses if we will print the per fold metrics or the total average metrics only\n",
    "    \"\"\"\n",
    "    \n",
    "    # This dict will be used to save the metrics of each fold\n",
    "    total_metrics_train = {\n",
    "        \"acc\": 0,\n",
    "        \"f1\": 0,\n",
    "        \"rec\": 0,\n",
    "        \"auc\": 0\n",
    "    }\n",
    "\n",
    "    total_metrics_test = {\n",
    "        \"acc\": 0,\n",
    "        \"f1\": 0,\n",
    "        \"rec\": 0,\n",
    "        \"auc\": 0\n",
    "    }\n",
    "\n",
    "    def calculate_metrics(y_true, y_pred, total_metrics, y_pred_probs=None, print_enabled=True):\n",
    "        # Calculate metrics\n",
    "        acc = metrics.accuracy_score(y_true, y_pred)\n",
    "        f1 = metrics.f1_score(y_true, y_pred)\n",
    "        rec = metrics.recall_score(y_true, y_pred)\n",
    "        if y_pred_probs is not None:\n",
    "            auc = metrics.roc_auc_score(y_true, y_pred_probs)\n",
    "\n",
    "        # Update total metrics\n",
    "        total_metrics['acc'] += acc\n",
    "        total_metrics['f1'] += f1\n",
    "        total_metrics['rec'] += rec\n",
    "        if y_pred_probs is not None:\n",
    "            total_metrics['auc'] += auc\n",
    "\n",
    "        # Print metrics\n",
    "        if print_enabled:\n",
    "            print(f'\\t\\tAccuraccy: {acc}')\n",
    "            print(f'\\t\\tRecall: {rec}')\n",
    "            print(f'\\t\\tF1_Score: {f1}')\n",
    "            if y_pred_probs is not None:\n",
    "                print(f'\\t\\tAUC: {auc}')\n",
    "\n",
    "    def print_total_metrics(total_metrics, splits):\n",
    "        print(f'\\tAccuraccy: {total_metrics[\"acc\"] / splits}')\n",
    "        print(f'\\tRecall: {total_metrics[\"rec\"] / splits}')\n",
    "        print(f'\\tF1_Score: {total_metrics[\"f1\"] / splits}')\n",
    "        if total_metrics['auc'] != 0:\n",
    "            print(f'\\tAUC: {total_metrics[\"auc\"] / splits}')\n",
    "\n",
    "    which_split = 0\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=True)\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        if verbose:\n",
    "            print(f'> Split: {which_split}')\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index].astype(int), y[test_index].astype(int)\n",
    "\n",
    "        # We will start with simple models like Logistic Regression\n",
    "        clf = estimator\n",
    "    \n",
    "        clf.fit(X_train, y_train)\n",
    "    \n",
    "        # Predict on training set\n",
    "        train_pred = clf.predict(X_train)\n",
    "        train_pred_proba = clf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "        # Predict on test set\n",
    "        test_pred = clf.predict(X_test)\n",
    "        test_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Metrics on the train set\n",
    "        if verbose:\n",
    "            print('\\tTraining Metrics')\n",
    "        calculate_metrics(y_train, train_pred, total_metrics_train, y_pred_probs=train_pred_proba, print_enabled=verbose)\n",
    "\n",
    "        # Metrics on the validation set\n",
    "        if verbose:\n",
    "            print('\\tValidation Metrics')\n",
    "        calculate_metrics(y_test, test_pred, total_metrics_test, y_pred_probs=test_pred_proba, print_enabled=verbose)\n",
    "\n",
    "        which_split += 1\n",
    "\n",
    "#     print(\">>> Total Metrics Train:\")\n",
    "#     print_total_metrics(total_metrics_train, which_split)\n",
    "    \n",
    "#     print(\">>> Total Metrics Test:\")\n",
    "#     print_total_metrics(total_metrics_test, which_split)\n",
    "    \n",
    "    return {'train': {k: v / folds for k, v in total_metrics_train.items()},\n",
    "            'test': {k: v / folds for k, v in total_metrics_test.items()}\n",
    "           }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning\n",
    "\n",
    "Although, above we have working code of fitting and evaluating a simple Logistic Regression model we must now focus on finding the best parameters for the model. Since our dataset is really small we can easily run GridSearch on all the the hyper parameters of LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T09:28:09.191239Z",
     "start_time": "2020-04-28T09:28:09.172848Z"
    }
   },
   "outputs": [],
   "source": [
    "def tuning(estimator, parameters, scores, X, y, verbose=True):\n",
    "    \"\"\"\n",
    "    Will run a GridSearch on the parameters of the given estimator and print the results and the best parameters\n",
    "    for each score we have given.\n",
    "    Care that the printed results are not sorted.\n",
    "    \n",
    "    Args:\n",
    "        estimator (estimator class): Class name implementing the scikit-learn estimator interface\n",
    "        parameters (dict): Dictionary of available parameters for the estimator\n",
    "        scores List[(str): List of string of metrics we want to maximize, ref:https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "        X (np.array): Our development training input\n",
    "        y (np.array): A vector of our development labels\n",
    "        verbose(boolean): Sets if we will be printing the results (default: True)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of metric names as keys and the best parameters as values\n",
    "    \"\"\"\n",
    "    best_params_list = []\n",
    "    for score in scores:\n",
    "        if verbose:\n",
    "            print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "            print()\n",
    "\n",
    "        cross_val = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "        \n",
    "        clf = GridSearchCV(\n",
    "            estimator(), parameters, scoring='%s' % score, cv=cross_val\n",
    "        )\n",
    "        clf.fit(X, y)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Best parameters set found on development set:\")\n",
    "            print()\n",
    "            print(clf.best_params_)\n",
    "        \n",
    "        best_params_list.append(clf.best_params_)\n",
    "        \n",
    "        if verbose:\n",
    "            print()\n",
    "            print(\"Grid scores on development set:\")\n",
    "            print()\n",
    "            means = clf.cv_results_['mean_test_score']\n",
    "            stds = clf.cv_results_['std_test_score']\n",
    "            for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "                print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                      % (mean, std * 2, params))\n",
    "            print('\\n')\n",
    "    \n",
    "    # Create the returned dictionary of \"metric\": best_params\n",
    "    return dict(zip(scores, best_params_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Having created modular methods for:\n",
    "* Creating the dataset\n",
    "* Tuning the hyperparameters\n",
    "* Evaluating the tuned parameters\n",
    "\n",
    "we will now combine them in one cell.  \n",
    "  \n",
    "**Disclaimer**: I have not included in the below part the creation of the `analysis_actors_dict` or the performing of the calculations on them, but they can be easily added on \"production\" code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T10:34:01.480017Z",
     "start_time": "2020-04-28T10:34:01.471502Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_pipeline(analysis_actors_dict, estimator, parameters, maximize=\"accuracy\", start=0, stop=2500):\n",
    "    \"\"\"\n",
    "    We run the pipeline creating the dataset, tuning a given estimator with a grid search\n",
    "    on the given parameters and evaluating the final model.\n",
    "    \n",
    "    Args:\n",
    "        analysis_actors_dict:  {\n",
    "                                    \"Agonists\": List[AnalysisActor.class]\n",
    "                                    \"Antagonists\": List[AnalysisActor.class]\n",
    "                                }\n",
    "        estimator(estimator class): Class name implementing the scikit-learn estimator interface (NOT Object)\n",
    "        parameters(dict): Dictionary of the grid of the paramateres we will run GridSearch on\n",
    "        start(int): Starting frame\n",
    "        stop(int): Ending frame\n",
    "        maximize (Str): The name of the metric we want to maximize and have the scores returned.\n",
    "                        Can be: \"accuracy\", \"f1\", \"recall\", \"roc_auc\"\n",
    "                        \n",
    "    Returns:\n",
    "        Dictionary of the metrics of the final model (chosen by the metric we want to maximize)\n",
    "    \n",
    "    \"\"\"\n",
    "    dataset_df = create_dataset(analysis_actors_dict, start=start, stop=stop)\n",
    "\n",
    "    # Separate training data from labels, the rows are fully separated meaning that \n",
    "    # first k rows are agonists and then we have the antagonists\n",
    "    X = np.array(dataset_df)[:, :-1]\n",
    "    y = np.array(dataset_df)[:, -1]\n",
    "\n",
    "#     iris = pd.read_csv(filepath_or_buffer='../datasets/misc/iris.csv')\n",
    "\n",
    "#     X = np.array(iris)[:, :-1]\n",
    "#     y = np.array(iris)[:, -1]\n",
    "\n",
    "    # Select which metrics we are trying to maximize\n",
    "    scores = [\"accuracy\", \"f1\", \"recall\", \"roc_auc\"]\n",
    "    \n",
    "    # This dictionary contains the best parameteres for each metric\n",
    "    best_params = tuning(estim, parameters, scores, X, y, verbose=False)\n",
    "\n",
    "    # Final evaluation on the best params for each metric\n",
    "    for score in scores:\n",
    "#         print(f'>>> Metric Maximized: {score}')\n",
    "        metric_scores = evaluate_params(estim(**best_params[score]), X, y, folds=5, verbose=False)\n",
    "        if score == maximize:\n",
    "            ret_scores = metric_scores\n",
    "#         print('\\n')\n",
    "        \n",
    "    return ret_scores\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing Windows and Rolling \n",
    "\n",
    "One of the main goals is to identify the earliest point (frames) of the simulation that we can distinguish an agonist from an antagonists.  \n",
    "  \n",
    "For that reason we are using two techiniques:\n",
    "* Increasing windows like 0 - 500, 0 - 1000, 0 - 2500 frames\n",
    "* Rolling windows like 0 - 500, 500 - 1000, 1000 - 1500 frames\n",
    "\n",
    "To do that for each feature we need an appropriate technique. Luckily, on Rg Mean, Std and SASA Mean, Std the technique is easy and similar. Since their values are timeseries of 2500 frames we just calculate the means, stds on the slice specified by the window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T10:13:30.405417Z",
     "start_time": "2020-04-28T10:13:30.388926Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select an estimator, CARE: We need the class and not an object eg LogistingRegression -> correct\n",
    "#                                                                   LogisticRegression() -> wrong\n",
    "estim = LogisticRegression\n",
    "\n",
    "# Select on which parameters we will perform Grid Search\n",
    "parameters = {\"C\":np.logspace(-5,1,7), \"penalty\":[\"l1\",\"l2\"], \"tol\": np.logspace(-9, -2, 8),\n",
    "             \"solver\":[\"liblinear\"], \"max_iter\": [100000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T10:45:34.855384Z",
     "start_time": "2020-04-28T10:34:04.526561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a0372897444410929eb09c9a718d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Increasing Window', max=5.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6958febac54ca9bc19084285fc3fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Rolling Window', max=5.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>auc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 - 500</td>\n",
       "      <td>0.560969</td>\n",
       "      <td>0.412024</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.638492</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 - 1000</td>\n",
       "      <td>0.575499</td>\n",
       "      <td>0.372222</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.613175</td>\n",
       "      <td>0.390476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 - 1500</td>\n",
       "      <td>0.560399</td>\n",
       "      <td>0.123922</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.560635</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.311111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0 - 2000</td>\n",
       "      <td>0.590883</td>\n",
       "      <td>0.293039</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.590714</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 - 2500</td>\n",
       "      <td>0.567806</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.572063</td>\n",
       "      <td>0.480952</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.261111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0 - 500</td>\n",
       "      <td>0.590883</td>\n",
       "      <td>0.493574</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.688889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>500 - 1000</td>\n",
       "      <td>0.590883</td>\n",
       "      <td>0.432246</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.636190</td>\n",
       "      <td>0.576190</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000 - 1500</td>\n",
       "      <td>0.560399</td>\n",
       "      <td>0.114980</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.500635</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.455556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1500 - 2000</td>\n",
       "      <td>0.597436</td>\n",
       "      <td>0.479522</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.688175</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.622222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000 - 2500</td>\n",
       "      <td>0.591168</td>\n",
       "      <td>0.342518</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.558016</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        window  accuracy_train  f1_train  recall_train  auc_train  \\\n",
       "0      0 - 500        0.560969  0.412024      0.366667   0.638492   \n",
       "1     0 - 1000        0.575499  0.372222      0.283333   0.613175   \n",
       "2     0 - 1500        0.560399  0.123922      0.083333   0.560635   \n",
       "3     0 - 2000        0.590883  0.293039      0.200000   0.590714   \n",
       "4     0 - 2500        0.567806  0.226667      0.150000   0.572063   \n",
       "5      0 - 500        0.590883  0.493574      0.450000   0.655556   \n",
       "6   500 - 1000        0.590883  0.432246      0.350000   0.636190   \n",
       "7  1000 - 1500        0.560399  0.114980      0.083333   0.500635   \n",
       "8  1500 - 2000        0.597436  0.479522      0.416667   0.688175   \n",
       "9  2000 - 2500        0.591168  0.342518      0.266667   0.558016   \n",
       "\n",
       "   accuracy_test   f1_test  recall_test  auc_test  \n",
       "0       0.547619  0.406667     0.333333  0.638889  \n",
       "1       0.390476  0.000000     0.000000  0.188889  \n",
       "2       0.452381  0.000000     0.000000  0.311111  \n",
       "3       0.452381  0.000000     0.000000  0.227778  \n",
       "4       0.480952  0.080000     0.066667  0.261111  \n",
       "5       0.571429  0.452381     0.466667  0.688889  \n",
       "6       0.576190  0.446667     0.466667  0.638889  \n",
       "7       0.476190  0.000000     0.000000  0.455556  \n",
       "8       0.633333  0.540000     0.466667  0.622222  \n",
       "9       0.571429  0.214286     0.200000  0.500000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We need the Reading part of the noteboo to be executed before this cell \n",
    "# so as we have the complete analysis_actors_dict\n",
    "final_results = []\n",
    "\n",
    "window_size = 500\n",
    "window_start_stop_points = np.arange(0, 2500, window_size)\n",
    "\n",
    "# Increasing window\n",
    "for start in tqdm(window_start_stop_points, desc=\"Increasing Window\"):\n",
    "    returned_scores = run_pipeline(analysis_actors_dict, estim, parameters, maximize=\"f1\", start=0, stop= start + window_size)\n",
    "    final_results.append([f\"0 - {start + window_size}\"] + list(returned_scores['train'].values()) + list(returned_scores['test'].values()))\n",
    "    \n",
    "# Rolling window\n",
    "for start in tqdm(window_start_stop_points, desc=\"Rolling Window\"):\n",
    "    returned_scores = run_pipeline(analysis_actors_dict, estim, parameters, maximize=\"f1\", start=start, stop= start + window_size)\n",
    "    final_results.append([f\"{start} - {start + window_size}\"] + list(returned_scores['train'].values()) + list(returned_scores['test'].values()))\n",
    "\n",
    "#  Create a DataFrame that summarizes the results over all the windows\n",
    "results_df = pd.DataFrame(final_results, columns=['window', 'accuracy_train', 'f1_train', 'recall_train', 'auc_train',\n",
    "                                                  'accuracy_test', 'f1_test', 'recall_test', 'auc_test'])\n",
    "                                                                                       \n",
    "display(results_df)                                                                                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('thesisEnv': virtualenv)",
   "language": "python",
   "name": "python36964bitthesisenvvirtualenv849bc23effdd4f5cbcfcfcad50606969"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
