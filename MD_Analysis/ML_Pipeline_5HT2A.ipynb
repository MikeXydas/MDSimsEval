{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning on 5HT2A Receptor\n",
    "\n",
    "Goal of this notebook is to use the features extracted and analyzed on the other Analysis notebook.  \n",
    "We want to differentiate agonist ligands from antagonists using features extracted from the MD simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T10:58:56.344095Z",
     "start_time": "2020-04-25T10:58:56.330394Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from AnalysisActor.AnalysisActorClass import AnalysisActor\n",
    "from AnalysisActor.utils import create_analysis_actor_dict\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "import logging\n",
    "import math\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T09:00:19.399539Z",
     "start_time": "2020-04-25T09:00:19.396637Z"
    }
   },
   "source": [
    "## Reading the Simulations\n",
    "\n",
    "We will use the `AnalysisActor` package I wrote which is able to extract on low level features from the simulations. I call it low level since for example the `AnalysisActor.class` of a ligand will give us the $Rg$ of the ligand on each frame. This must be then reduced to features that I have analyzed like mean and std for each ligand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T09:10:37.998346Z",
     "start_time": "2020-04-25T09:07:52.992539Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Agonists | Lorcaserin:   7%|▋         | 1/15 [00:03<00:42,  3.05s/it]/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/MDAnalysis/lib/mdamath.py:259: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  alpha = np.rad2deg(np.arccos(np.dot(y, z) / (ly * lz)))\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/MDAnalysis/lib/mdamath.py:260: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  beta = np.rad2deg(np.arccos(np.dot(x, z) / (lx * lz)))\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/MDAnalysis/lib/mdamath.py:261: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  gamma = np.rad2deg(np.arccos(np.dot(x, y) / (lx * ly)))\n",
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/MDAnalysis/lib/mdamath.py:264: RuntimeWarning: invalid value encountered in greater\n",
      "  if np.all(box > 0.0) and alpha < 180.0 and beta < 180.0 and gamma < 180.0:\n",
      "Agonists | Donitriptan: 100%|██████████| 15/15 [00:48<00:00,  3.23s/it]  \n",
      "Antagonists | Ziprasione: 100%|██████████| 18/18 [01:56<00:00,  6.47s/it]   \n"
     ]
    }
   ],
   "source": [
    "# Reading the simulations\n",
    "analysis_actors_dict = create_analysis_actor_dict('../datasets/New_AI_MD/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `analysis_actors_dict` is a dictionary:\n",
    "```python \n",
    "{\n",
    "    \"Agonists\": List[AnalysisActor.class]\n",
    "    \"Antagonists\": List[AnalysisActor.class]\n",
    "}\n",
    "```\n",
    "This dictionary currently has only read the trajectories and has not calculated any of its metrics.  In order to do that we must call the `AnalysisActor.perform_analysis` method, which takes as an argument a list of metrics to be calculated.  \n",
    "  \n",
    "**Care**: The calculations need memory in order to be calculated and stored, so monitor the memory usage. If this becomes too big of a problem we can solve it in a \"dynamic\" way meaning that we will not keep saved the trajectories but demand them briefly for the calculations to be executed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T09:16:30.886963Z",
     "start_time": "2020-04-25T09:15:04.497527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b0de987063464f8df6d1c5d2ab3f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ligand Calculations', max=33.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Possible arguments for \"metrics\" list:\n",
    "#     Empty List [] (default): All of the available metrics will be calculated\n",
    "#     'Rg': Radius of Gyration\n",
    "#     'RMSF': Root Mean Square Fluctuations\n",
    "#     'SASA': Solven Accessible Surface Area\n",
    "#     'PCA': Principal Component Analysis\n",
    "#     'Hbonds': Hydrogen Bonds\n",
    "#     'Salt': Calculate number of salt bridges\n",
    "\n",
    "# Iterate on all the ligands\n",
    "for which_ligand in tqdm(analysis_actors_dict['Agonists'] + analysis_actors_dict['Antagonists'], desc=\"Ligand Calculations\"):\n",
    "    which_ligand.perform_analysis(metrics=[\"Rg\", \"SASA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the Features\n",
    "\n",
    "From the calculations we must now extract ML appropriate features. The features used in our case are:\n",
    "* Mean of Rg\n",
    "* Std of Rg\n",
    "* Mean of SASA\n",
    "* Std of SASA\n",
    "\n",
    "One parameter one must think of is the window of the features. Our simulations are of 2.500 and using all of them may  not be ideal. Our analysis actually shows that the event happens after 1.200 frames in most cases. However, as a starting point we will use all of the frames.  \n",
    "  \n",
    "**As labels we will use:**\n",
    "* Agonist: 1\n",
    "* Antagonist: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T09:57:58.249868Z",
     "start_time": "2020-04-25T09:57:58.196118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RgMean</th>\n",
       "      <th>RgStd</th>\n",
       "      <th>SASAMean</th>\n",
       "      <th>SASAstd</th>\n",
       "      <th>LigandLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.919072</td>\n",
       "      <td>0.087596</td>\n",
       "      <td>156.570844</td>\n",
       "      <td>2.668977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.012352</td>\n",
       "      <td>0.100447</td>\n",
       "      <td>157.272992</td>\n",
       "      <td>3.496758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.066259</td>\n",
       "      <td>0.139269</td>\n",
       "      <td>158.865216</td>\n",
       "      <td>3.338327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.054636</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>160.425158</td>\n",
       "      <td>3.087227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.065666</td>\n",
       "      <td>0.086757</td>\n",
       "      <td>160.093780</td>\n",
       "      <td>2.563157</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.987462</td>\n",
       "      <td>0.091215</td>\n",
       "      <td>155.726417</td>\n",
       "      <td>2.701195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21.111873</td>\n",
       "      <td>0.072859</td>\n",
       "      <td>157.394022</td>\n",
       "      <td>2.367292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.056187</td>\n",
       "      <td>0.121940</td>\n",
       "      <td>157.885306</td>\n",
       "      <td>3.425428</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.954715</td>\n",
       "      <td>0.082948</td>\n",
       "      <td>155.381640</td>\n",
       "      <td>2.691224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.879540</td>\n",
       "      <td>0.073616</td>\n",
       "      <td>153.995794</td>\n",
       "      <td>2.660802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20.938047</td>\n",
       "      <td>0.092146</td>\n",
       "      <td>152.506776</td>\n",
       "      <td>4.338009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20.943903</td>\n",
       "      <td>0.099227</td>\n",
       "      <td>155.428932</td>\n",
       "      <td>2.356847</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20.927188</td>\n",
       "      <td>0.086234</td>\n",
       "      <td>158.964340</td>\n",
       "      <td>2.383704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20.980655</td>\n",
       "      <td>0.087135</td>\n",
       "      <td>151.786571</td>\n",
       "      <td>2.673300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20.967914</td>\n",
       "      <td>0.071496</td>\n",
       "      <td>151.781082</td>\n",
       "      <td>2.278896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20.958812</td>\n",
       "      <td>0.081318</td>\n",
       "      <td>155.719152</td>\n",
       "      <td>2.914043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21.016318</td>\n",
       "      <td>0.065391</td>\n",
       "      <td>155.450683</td>\n",
       "      <td>2.421157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20.889419</td>\n",
       "      <td>0.088487</td>\n",
       "      <td>155.573505</td>\n",
       "      <td>2.354544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21.002299</td>\n",
       "      <td>0.091526</td>\n",
       "      <td>158.812646</td>\n",
       "      <td>2.844600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21.201915</td>\n",
       "      <td>0.168671</td>\n",
       "      <td>163.416459</td>\n",
       "      <td>3.164729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.911233</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>154.398714</td>\n",
       "      <td>2.800358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21.040147</td>\n",
       "      <td>0.123902</td>\n",
       "      <td>156.884367</td>\n",
       "      <td>4.297389</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20.938539</td>\n",
       "      <td>0.079991</td>\n",
       "      <td>158.054991</td>\n",
       "      <td>2.331026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20.975891</td>\n",
       "      <td>0.077284</td>\n",
       "      <td>153.170121</td>\n",
       "      <td>2.555843</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20.855814</td>\n",
       "      <td>0.084544</td>\n",
       "      <td>152.594985</td>\n",
       "      <td>2.959461</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20.905706</td>\n",
       "      <td>0.071585</td>\n",
       "      <td>155.664783</td>\n",
       "      <td>2.356071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20.926310</td>\n",
       "      <td>0.096954</td>\n",
       "      <td>153.860887</td>\n",
       "      <td>2.708510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>21.062499</td>\n",
       "      <td>0.068628</td>\n",
       "      <td>157.254017</td>\n",
       "      <td>2.371737</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20.863230</td>\n",
       "      <td>0.070291</td>\n",
       "      <td>155.142044</td>\n",
       "      <td>2.735512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20.969118</td>\n",
       "      <td>0.092476</td>\n",
       "      <td>153.039195</td>\n",
       "      <td>3.692342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20.980286</td>\n",
       "      <td>0.082861</td>\n",
       "      <td>158.802232</td>\n",
       "      <td>2.583116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>21.047709</td>\n",
       "      <td>0.084841</td>\n",
       "      <td>158.499460</td>\n",
       "      <td>2.683696</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20.888927</td>\n",
       "      <td>0.073659</td>\n",
       "      <td>153.958906</td>\n",
       "      <td>2.645135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RgMean     RgStd    SASAMean   SASAstd  LigandLabel\n",
       "0   20.919072  0.087596  156.570844  2.668977            1\n",
       "1   21.012352  0.100447  157.272992  3.496758            1\n",
       "2   21.066259  0.139269  158.865216  3.338327            1\n",
       "3   21.054636  0.099477  160.425158  3.087227            1\n",
       "4   21.065666  0.086757  160.093780  2.563157            1\n",
       "5   20.987462  0.091215  155.726417  2.701195            1\n",
       "6   21.111873  0.072859  157.394022  2.367292            1\n",
       "7   21.056187  0.121940  157.885306  3.425428            1\n",
       "8   20.954715  0.082948  155.381640  2.691224            1\n",
       "9   20.879540  0.073616  153.995794  2.660802            1\n",
       "10  20.938047  0.092146  152.506776  4.338009            1\n",
       "11  20.943903  0.099227  155.428932  2.356847            1\n",
       "12  20.927188  0.086234  158.964340  2.383704            1\n",
       "13  20.980655  0.087135  151.786571  2.673300            1\n",
       "14  20.967914  0.071496  151.781082  2.278896            1\n",
       "15  20.958812  0.081318  155.719152  2.914043            0\n",
       "16  21.016318  0.065391  155.450683  2.421157            0\n",
       "17  20.889419  0.088487  155.573505  2.354544            0\n",
       "18  21.002299  0.091526  158.812646  2.844600            0\n",
       "19  21.201915  0.168671  163.416459  3.164729            0\n",
       "20  20.911233  0.072906  154.398714  2.800358            0\n",
       "21  21.040147  0.123902  156.884367  4.297389            0\n",
       "22  20.938539  0.079991  158.054991  2.331026            0\n",
       "23  20.975891  0.077284  153.170121  2.555843            0\n",
       "24  20.855814  0.084544  152.594985  2.959461            0\n",
       "25  20.905706  0.071585  155.664783  2.356071            0\n",
       "26  20.926310  0.096954  153.860887  2.708510            0\n",
       "27  21.062499  0.068628  157.254017  2.371737            0\n",
       "28  20.863230  0.070291  155.142044  2.735512            0\n",
       "29  20.969118  0.092476  153.039195  3.692342            0\n",
       "30  20.980286  0.082861  158.802232  2.583116            0\n",
       "31  21.047709  0.084841  158.499460  2.683696            0\n",
       "32  20.888927  0.073659  153.958906  2.645135            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the features on the agonists\n",
    "start, stop = [0, 2500]\n",
    "\n",
    "full_dataset = []\n",
    "\n",
    "# Iterate on the agonists\n",
    "for which_ligand in analysis_actors_dict['Agonists']:\n",
    "    # Rg\n",
    "    mean_rg = np.mean(which_ligand.get_radius_of_gyration()[start:stop])\n",
    "    std_rg = np.std(which_ligand.get_radius_of_gyration()[start:stop])\n",
    "    \n",
    "    # SASA\n",
    "    mean_sasa = np.mean(which_ligand.get_sasa()[1][start:stop])\n",
    "    std_sasa = np.std(which_ligand.get_sasa()[1][start:stop])\n",
    "   \n",
    "    # For each ligand we will create a vector of [Mean Rg, Std Rg, Mean SASA, Std SASA, Ligand_Label]\n",
    "    full_dataset.append([mean_rg, std_rg, mean_sasa, std_sasa, 1])\n",
    "    \n",
    "# Iterate on the antagonists\n",
    "for which_ligand in analysis_actors_dict['Antagonists']:\n",
    "    # Rg\n",
    "    mean_rg = np.mean(which_ligand.get_radius_of_gyration()[start:stop])\n",
    "    std_rg = np.std(which_ligand.get_radius_of_gyration()[start:stop])\n",
    "    \n",
    "    # SASA\n",
    "    mean_sasa = np.mean(which_ligand.get_sasa()[1][start:stop])\n",
    "    std_sasa = np.std(which_ligand.get_sasa()[1][start:stop])\n",
    "   \n",
    "    # For each ligand we will create a vector of [Mean Rg, Std Rg, Mean SASA, Std SASA, Ligand_Label]\n",
    "    full_dataset.append([mean_rg, std_rg, mean_sasa, std_sasa, 0])\n",
    "    \n",
    "dataset_df = pd.DataFrame(full_dataset, columns=['RgMean', 'RgStd', 'SASAMean', 'SASAstd', 'LigandLabel'])\n",
    "\n",
    "display(dataset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and Training\n",
    "\n",
    "\n",
    "The main problem in our task is the little number of data points. This means that a good (or bad) result may be random and not reflect the reality. Taking that into account we will apply known techniques in order to be as general as possible using k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris dataset is used for debugging\n",
    "iris = pd.read_csv(filepath_or_buffer='../datasets/misc/iris.csv')\n",
    "\n",
    "X = np.array(iris)[:, :-1]\n",
    "y = np.array(iris)[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T11:47:23.833322Z",
     "start_time": "2020-04-25T11:47:23.700723Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Split: 0\n",
      "\tTraining Metrics\n",
      "\t\tAccuraccy: 0.5\n",
      "\t\tRecall: 0.08333333333333333\n",
      "\t\tF1_Score: 0.13333333333333333\n",
      "\t\tAUC: 0.5773809523809523\n",
      "\tValidation Metrics\n",
      "\t\tAccuraccy: 0.5714285714285714\n",
      "\t\tRecall: 0.0\n",
      "\t\tF1_Score: 0.0\n",
      "\t\tAUC: 0.3333333333333333\n",
      "> Split: 1\n",
      "\tTraining Metrics\n",
      "\t\tAccuraccy: 0.6538461538461539\n",
      "\t\tRecall: 0.4166666666666667\n",
      "\t\tF1_Score: 0.5263157894736842\n",
      "\t\tAUC: 0.6607142857142857\n",
      "\tValidation Metrics\n",
      "\t\tAccuraccy: 0.42857142857142855\n",
      "\t\tRecall: 0.3333333333333333\n",
      "\t\tF1_Score: 0.3333333333333333\n",
      "\t\tAUC: 0.25\n",
      "> Split: 2\n",
      "\tTraining Metrics\n",
      "\t\tAccuraccy: 0.5769230769230769\n",
      "\t\tRecall: 0.25\n",
      "\t\tF1_Score: 0.35294117647058826\n",
      "\t\tAUC: 0.5833333333333334\n",
      "\tValidation Metrics\n",
      "\t\tAccuraccy: 0.42857142857142855\n",
      "\t\tRecall: 0.0\n",
      "\t\tF1_Score: 0.0\n",
      "\t\tAUC: 0.25\n",
      "> Split: 3\n",
      "\tTraining Metrics\n",
      "\t\tAccuraccy: 0.5555555555555556\n",
      "\t\tRecall: 0.0\n",
      "\t\tF1_Score: 0.0\n",
      "\t\tAUC: 0.5722222222222222\n",
      "\tValidation Metrics\n",
      "\t\tAccuraccy: 0.5\n",
      "\t\tRecall: 0.0\n",
      "\t\tF1_Score: 0.0\n",
      "\t\tAUC: 0.4444444444444444\n",
      "> Split: 4\n",
      "\tTraining Metrics\n",
      "\t\tAccuraccy: 0.6296296296296297\n",
      "\t\tRecall: 0.5\n",
      "\t\tF1_Score: 0.5454545454545454\n",
      "\t\tAUC: 0.6500000000000001\n",
      "\tValidation Metrics\n",
      "\t\tAccuraccy: 0.16666666666666666\n",
      "\t\tRecall: 0.0\n",
      "\t\tF1_Score: 0.0\n",
      "\t\tAUC: 0.11111111111111112\n",
      "> Total Metrics\n",
      "\tAccuraccy: 0.5831908831908832\n",
      "\tRecall: 0.25\n",
      "\tF1_Score: 0.3116089689464302\n",
      "\tAUC: 0.6087301587301589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikexydas/pythonEnvs/thesisEnv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Separate training data from labels, the rows are fully separated meaning that \n",
    "# first k rows are agonists and then we have the antagonists\n",
    "X = np.array(dataset_df)[:, :-1]\n",
    "y = np.array(dataset_df)[:, -1]\n",
    "\n",
    "\n",
    "# This dict will be used to save the metrics of each fold\n",
    "total_metrics_train = {\n",
    "    \"acc\": 0,\n",
    "    \"f1\": 0,\n",
    "    \"rec\": 0,\n",
    "    \"auc\": 0\n",
    "}\n",
    "\n",
    "total_metrics_test = {\n",
    "    \"acc\": 0,\n",
    "    \"f1\": 0,\n",
    "    \"rec\": 0,\n",
    "    \"auc\": 0\n",
    "}\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, total_metrics, y_pred_probs=None, print_enabled=True):\n",
    "    # Calculate metrics\n",
    "    acc = metrics.accuracy_score(y_true, y_pred)\n",
    "    f1 = metrics.f1_score(y_true, y_pred)\n",
    "    rec = metrics.recall_score(y_true, y_pred)\n",
    "    if y_pred_probs is not None:\n",
    "        auc = metrics.roc_auc_score(y_true, y_pred_probs)\n",
    "    \n",
    "    # Update total metrics\n",
    "    total_metrics['acc'] += acc\n",
    "    total_metrics['f1'] += f1\n",
    "    total_metrics['rec'] += rec\n",
    "    if y_pred_probs is not None:\n",
    "        total_metrics['auc'] += auc\n",
    "    \n",
    "    # Print metrics\n",
    "    if print_enabled:\n",
    "        print(f'\\t\\tAccuraccy: {acc}')\n",
    "        print(f'\\t\\tRecall: {rec}')\n",
    "        print(f'\\t\\tF1_Score: {f1}')\n",
    "        if y_pred_probs is not None:\n",
    "            print(f'\\t\\tAUC: {auc}')\n",
    "    \n",
    "def print_total_metrics(total_metrics, splits):\n",
    "    print('> Total Metrics')\n",
    "    print(f'\\tAccuraccy: {total_metrics[\"acc\"] / splits}')\n",
    "    print(f'\\tRecall: {total_metrics[\"rec\"] / splits}')\n",
    "    print(f'\\tF1_Score: {total_metrics[\"f1\"] / splits}')\n",
    "    if total_metrics['auc'] != 0:\n",
    "        print(f'\\tAUC: {total_metrics[\"auc\"] / splits}')\n",
    "    \n",
    "which_split = 0\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print(f'> Split: {which_split}')\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index].astype(int), y[test_index].astype(int)\n",
    "    \n",
    "    # We will start with simple models like Logistic Regression\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on training set\n",
    "    train_pred = clf.predict(X_train)\n",
    "    train_pred_proba = clf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "    # Predict on test set\n",
    "    test_pred = clf.predict(X_test)\n",
    "    test_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Metrics on the train set\n",
    "    print('\\tTraining Metrics')\n",
    "    calculate_metrics(y_train, train_pred, total_metrics_train, y_pred_probs=train_pred_proba, print_enabled=True)\n",
    "    \n",
    "    # Metrics on the validation set\n",
    "    print('\\tValidation Metrics')\n",
    "    calculate_metrics(y_test, test_pred, total_metrics_test, y_pred_probs=test_pred_proba, print_enabled=True)\n",
    "    \n",
    "    which_split += 1\n",
    "    \n",
    "print_total_metrics(total_metrics_train, which_split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('thesisEnv': virtualenv)",
   "language": "python",
   "name": "python36964bitthesisenvvirtualenv849bc23effdd4f5cbcfcfcad50606969"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
